---
title: "Natural Language Processing"
slug: "11_ai/0_gen_ai/0_large_language_model/0_natural_laguage_processing"
stack: "GenAI"
---

- Dive into the realm of **Natural Language Processing** aka `NLP` and its importance when working with **Large Language Model**s aka `LLM`s.
- Discover how `LLM`s process and generate text that mimics human language, and learn about the advancements in multimodal `LLM`s capable of interpreting image, audio, and video data.

## Introduction to NLP

NLP is a specialized field with AI
NLP is a digital translator between Human and Computer.
NPL enables Computer to understand, interprete and even generate human language thru use of specific aglorithms and models

Eg. HealthCare, NLP is the process that allows computer system to

![Interaction between computer and human become more natural, efficient and beneficial](../../../../../src/images/ai/gen_ai/gi-2.png)

- Read and understand doctor's notes from medical records
- Extract important information like symptoms, diagnosis and treatments
- Generate summary report

## `LLM`s

![Large Language Model](../../../../../src/images/ai/gen_ai/gi-3.png)

- receive **input** and produce **output** in human language
- defined by their **parameters**
- Multi-model LLMs also parse: Advance AI models capable of generating content across multiple type of data like image, audio, text, etc

✏️: Not all `app`s require multi-modal capability, many tasks can be handled with text based models. As of 2023, GPT is predemoinent model used for chatbots

![Improvements in power, computer and lessons learned about LLM drive change](../../../../../src/images/ai/gen_ai/gi-1.png)

eg. Bloomberg GPT (2022-23)

- 50 billion parameter LLM build for financial industry
- training on 40 years of clean finance specific data
- Training on open-source diverse in-house data
- smaller model but improved performance

**Latest LLMs**

- Better at
  - Thinking more logically
  - Being fair and unbiased
- learning from
  - text
  - sounds
  - pictures
  - videos
- `LLM`s are powerful `neural network`s desgined to understand and generate human like text
- `LLM`s learn from vast amount of

  - Text Data
  - Capturing Grammer
  - Context
  - Semantics

- The **G**enerative **P**re-Trainined **T**ransformer aka `GPT` series is a prominent example of `LLM`s

- Transformer can generate tasks like
  - Translations
  - Summarization
  - Creating Writing

### LLM Lifecycle

- Learning from Data
  - model acquire language pattern and representations from vast amount of unlabled text data
- Specializing for tasks
  - they train on labeled data such as sentiment analysis and translationt o specialize for specific tasks
- Generating Responses

### LLMs find applications in various NLP tasks

including

- Text generation
- Translation
- Questions answering
- Chatbots

We will cover **AI Lifecycle for LLMs** including

- Traning
- Customizing
- Inferencing
